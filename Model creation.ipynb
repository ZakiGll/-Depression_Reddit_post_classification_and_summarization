{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "885d9db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "779c71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('depression_dataset_reddit_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "81828a5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7731, 2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3ffd7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_text']\n",
    "y = df['is_depression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d12f4f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 250000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eea22681",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
    "                               output_sequence_length=1800,\n",
    "                               output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7c860b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data = keras.preprocessing.sequence.pad_sequences(data_sequences, maxlen=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "28ab675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)\n",
    "vectorized_text = vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "140d3112",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(7731)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e96c92a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.7))\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8469220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_FEATURES+1, 32))\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4ea9e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e1194912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 503s 1s/step - loss: 0.2648 - accuracy: 0.8937 - val_loss: 0.0776 - val_accuracy: 0.9766\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs=1, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e385133f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 12s 249ms/step - loss: 0.1063 - accuracy: 0.9701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10632096976041794, 0.9700520634651184]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8f6ec2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "56c51fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models', 'Depression_text_classification.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a91c9d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = vectorizer('i`m really thankfful about what i have in my life')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0510cd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 110,  181,  469,    9,  604,   83,   56,  252,  369,   45,   35,\n",
       "        178,    3,  821,    6,  328,   57,   66,  438, 2566,  362,   29,\n",
       "          6,  355,   64,   13,   11,   15,   42,   16,   21,   84,   83,\n",
       "       3428,   56,  152,  181,   16,  733,    4,   26, 2083,   65,    9,\n",
       "         33,    0,    0,    0,    0,    0], dtype=int64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.numpy()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2464bfb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 135ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(np.expand_dims(text,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "da817a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is : Not depressed\n"
     ]
    }
   ],
   "source": [
    "if res > 0.5 :\n",
    "    print(\"The predicted class is : Depressed\") \n",
    "else:\n",
    "    print(\"The predicted class is : Not depressed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
